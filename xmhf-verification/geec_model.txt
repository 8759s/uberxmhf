GEEC model (in text)
author: amit vasudevan (amitvasudevan@acm.org)


Notes:
    1. l_xxx => local variable
    2. g_xxx => global variable
    3. hw.xxx => hardware component/state variable


MAX_CPUS = max. no. of platform cpus
MAX_STACKSIZE = size of stack in bytes
ADDR_4GB_PAGES = (0x100000000ULL/0x1000) = max. 4K pages in 4GB memory address space
PAGES(memextent) = memory page range (x..y) for a given memory extent (memextent)
ADDRS(memextent) = memory address range (mx..my) for a given memory extent (memextent)

g_totalslabs;
g_sinfotable[1..g_totalslabs]{
    .s_type (s_verified, s_unverified, s_unverified_guest);
    .s_codeextents;
    .s_dataextents;
    .s_stackextents;
    .s_dmadataextents;
    .s_deviceallocations;
    .s_iotblbase;
    .s_mempgtblbase;
}

type oparams = byte [];
type iparams = byte [];
type siparams = {
    .ctype;
    .caller;
    .callee;
    .param_buf
}

type soparams = {
    .param_buf
}


//////
// geec prime (gp)
//////


g_stack[0..MAX_CPUS-1][MAX_STACKSIZE];
g_temp_mempgtbl[0..ADDR_4GB_PAGES]{
    .addr;
    .flags (f_readwrite, f_readonly, f_noexecute, f_present, f_super, f_user);
};
g_sysdevlist; //list of system devices
g_sysdevlist_count; //count of system devices
g_iotbl[0..MAXCPUS-1][MAX_IOTBLSIZE];
g_slabdevicemapping[0..g_totalslabs-1];

entrystub {
    l_cpuid = hw.lapic.id;
    hw.cpu.esp = g_stack[cpuid];
	slab_main();
    halt();
}


slab_main {
    //setup temporary unity mapped page-tables
    gp_setup_temp_mempgtbl();

    //sanity check hw requirements
    gp_sanitycheck_hw_requirements();

    //setup slab device allocations
    gp_setup_slab_device_allocations();

    //setup slab memory page tables
    gp_setup_slab_mempgtbl();

	//load verified slabs' memory page table
	hw.cpu.cr3 = g_sinfotable[GEEC_PRIME].s_mempgtblbase;

    //setup cpu state and transfer control to init slab
    gp_setup_cpustate_and_replicate();

    halt();
}


//setup temporary unity mapped page-tables
gp_setup_temp_pagetables {
    for (l_i=0; l_i < g_totalslabs; l_i++){
        g_temp_mempgtbl[PAGES(sinfotable[l_i].codeextents)].addr = ADDRS(sinfotable[l_i].codeextents);
        g_temp_mempgtbl[PAGES(sinfotable[l_i].codeextents)].flags = (f_present | f_readonly | f_super);
        g_temp_mempgtbl[PAGES(sinfotable[l_i].dataextents)].addr = ADDRS(sinfotable[l_i].dataextents);
        g_temp_mempgtbl[PAGES(sinfotable[l_i].dataextents)].flags = (f_present | f_readwrite | f_noexecute | f_super);
        g_temp_mempgtbl[PAGES(sinfotable[l_i].stackextents)].addr = ADDRS(sinfotable[l_i].stackextents);
        g_temp_mempgtbl[PAGES(sinfotable[l_i].stackextents)].flags = (f_present | f_readwrite | f_noexecute | f_super);
        g_temp_mempgtbl[PAGES(sinfotable[l_i].dmadataextents)].addr = ADDRS(sinfotable[l_i].stackextents);
        g_temp_mempgtbl[PAGES(sinfotable[l_i].dmadataextents)].flags = (f_present | f_readwrite | f_noexecute | f_super);
    }

    g_temp_mempgtbl[PAGES(~sinfotable[0..(g_totalslabs-1)].{code,data,stack,dmadata}extents)].addr = ADDRS(~sinfotable[0..(g_totalslabs-1)].{code,data,stack,dmadata}extents);
    g_temp_mempgtbl[PAGES(~sinfotable[0..(g_totalslabs-1)].{code,data,stack,dmadata}extents)].flags = (f_present | f_readwrite | f_noexecute | f_super);

    hw.cpu.msr_efer |= NX;
    hw.cpu.cr4 |= PAE, PSE;
	hw.cpu.cr3 = g_temp_mempgtbl;
    hw.cpu.cr0 |= PG;
}


//setup slab device allocations
gp_setup_slab_device_allocations {
    //enumerate system devices and setup g_sysdevlist and g_sysdevlist_count
    gp_enumerate_system_devices();

    //setup slab device mappings based on system devices and individual slab device allocations
    for(l_i=0; l_i < g_totalslabs; l_i++){
        g_slabdevicemapping[l_i] = gp_getslabdevicemapping(g_sysdevlist, g_sinfotable[l_i].deviceallocations);
    }
    l_iommutablebase = gp_call_slab(UAPI_DEVPGTBL, UAPI_DEVPGTBL_INIT);

	//iv. For all slabs: call_slab(uapi_devpgtbl, DEVPGTBL_INITTBL);
    for(l_i=0; l_i < g_totalslabs; l_i++){
        gp_call_slab(UAPI_DEVPGTBL, UAPI_DEVPGTBL_INITTABLE, l_i);
    }

    //v. Initialize IOMMU
    hw.iommu.tablebase = l_iommutablebase;
	hw.iommu.translationenable = true

	for(l_i=0; l_i < g_sysdevlist_count; l_i++){
        if( (l_slabid = gp_getslabid_for_device(g_sysdevlist[l_i])) in 0..g_totalslabs ) {
            gp_call_slab(UAPI_DEVPGTBL, UAPI_DEVPGTBL_BINDDEVICE, l_slabid, g_sysdevllist[l_i]);
        }
	}
}

//setup (unverified) slab legacy I/O table
gp_setup_slab_iotbl {

    for(l_i=0; l_i < g_totalslabs; l_i++){
        if(g_sinfotable[l_i].s_type == s_unverified || s_unverified_guest){
            gp_call_slab(UAPI_IOTBL, UAPI_IOTBL_INIT, l_i);
            for(l_k=0; l_k <  g_slabdevicemapping[l_i].devcount; l_k++){
                gp_call_slab(UAPI_IOTBL, UAPI_IOTBL_ALLOWACCESSTOPORT, l_i, g_slabdevicemapping[l_i].device[l_k].ports);
            }
        }
    }

}


oparams gp_call_slab(callee, callee_fn, iparams){
    l_soparams, l_siparams;

    l_siparams.caller = GEEC_PRIME;
    l_siparams.callee = callee;
    l_siparams.callee_fn = callee_fn;
    l_siparams.parambuf = iparams;

    call_sentinel(ls_iparams, l_soparams);

    return l_soparams.parambuf;
}


call_sentinel (siparams, soparams) {
    siparams.ctype = CALL_FROM_VERIFIED;
    l_caller_stackframe = current stack frame;
	geec_sentinel_verified_ep(l_caller_stackframe);
}



gp_setup_slab_mempgtbl {

    gp_call_slab(UAPI_MEMPGTBL, UAPI_MEMPGTBL_INITTABLE, GEEC_PRIME);
    gp_setup_slab_mempgtbl_populate_pt(GEEC_PRIME);
    for(l_i=0; l_i < g_totalslabs; l_i++){
        if( g_sinfotable[l_i].s_type == s_unverified || s_unverified_guest ){
            gp_call_slab(UAPI_MEMPGTBL, UAPI_MEMPGTBL_INITTABLE, l_i);
            gp_setup_slab_mempgtbl_populate_pt(l_i);
        }
    }
}

gp_setup_slab_mempgtbl_populate_pt (slabid) {

    l_slabtype = g_sinfotable[slabid].s_type;
    for(l_spa=0; l_spa < ADDR_4GB; l_spa += PAGE_SIZE_4K){
        l_spa_slabregion, l_spa_slabtype, l_spa_sameslab = gp_setup_slab_mempgtbl_getspatype(slabid, l_spa);
        l_flags = gp_setup_slab_mempgtbl_getflagsforspa(slabid, l_spa_slabregion, l_spa_slabtype, l_spa_sameslab);
        if( l_spa_slabregion == REGION_IOTBL && l_slabtype != s_verified)
            gp_call_slab(UAPI_MEMPGTBL, UAPI_MEMPGTBL_SETENTRYFORPADDR, l_spa, g_sinfotable[slabid].s_iotblbase, l_flags);
        else
            gp_call_slab(UAPI_MEMPGTBL, UAPI_MEMPGTBL_SETENTRYFORPADDR, l_spa, l_spa, l_flags);
    }

}


gp_setup_slab_mempgtbl_getspatype(slabid, spa) {

   for(l_i=0; l_i < g_totalslabs; l_i++){
    switch (spa) {
        case spa in g_iotbl[]:
            return REGION_IOTBL, s_not_a_slab, false;
        case spa in g_slabdevicemapping[l_i].device[0..devcount].mmioregions:
            return REGION_DEVMMIO, sinfotable[l_i].s_type, ((l_i == slabid) ? true : false);
        case spa in g_sinfotable[l_i].codeextents
            return REGION_CODE, sinfotable[l_i].s_type, ((l_i == slabid) ? true : false);
        case spa in g_sinfotable[l_i].dataextents
            return REGION_DATA, sinfotable[l_i].s_type, ((l_i == slabid) ? true : false);
        case spa in g_sinfotable[l_i].stackextents
            return REGION_STACK, sinfotable[l_i].s_type, ((l_i == slabid) ? true : false);
        case spa in g_sinfotable[l_i].dmadataextents
            return REGION_DMADATA, sinfotable[l_i].s_type, ((l_i == slabid) ? true : false);
        default
            return REGION_OTHER, s_not_a_slab, false;
    }
   }

}


gp_setup_slab_mempgtbl_getflagsforspa(slabid, spa_slabregion, spa_slabtype, spa_sameslab) {
    l_flags=0;

    switch(g_sinfotable[slabid].s_type){
        case s_verified:
            if(spa_slabregion == REGION_OTHER){
                l_flags = f_present + f_readwrite + f_super;
            }else{
                if(spa_sameslab || spa_slabtype == s_verified){
                    switch(spa_slabregion){
                        case REGION_CODE:
                            l_flags = f_present + f_readonly + f_super;
                        case REGION_DATA:
                        case REGION_STACK:
                        case REGION_DMADATA:
                            l_flags = f_present + f_readwrite + f_noexecute + f_super;
                        case REGION_MMIO:
                            l_flags = f_present + f_readwrite + f_noexecute + f_super;
                    }
                }else{
                    l_flags = f_present + f_readwrite + f_noexecute + f_super;
                }
            }
            break;

        case s_unverified:
            if(spa_slabregion == REGION_OTHER){
                l_flags = f_present + f_readwrite + f_super;
            }else{
                if(spa_sameslab || spa_slabtype == s_verified){
                    switch(spa_slabregion){
                        case REGION_CODE:
                            l_flags = f_present + f_readonly + f_super;
                        case REGION_DATA:
                        case REGION_STACK:
                        case REGION_DMADATA:
                            l_flags = f_present + f_readwrite + f_noexecute + f_super;
                        case REGION_MMIO:
                            l_flags = f_present + f_readwrite + f_noexecute + f_super;
                    }

                    if(spa_sameslab) l_flags += f_user;
                }else{
                    l_flags = f_present + f_readwrite + f_noexecute + f_super;
                }
            }
            break;

        case s_unverified guest:
            if(spa_sameslab && spa_slabregion != REGION_OTHER){
                l_flags = f_present + f_readwrite;
            }else{
                l_flags =0;
            }
            break;
    }

   return l_flags;
}


gp_setup_cpustate_and_replicate {
    //initialize GDT
    g_gdt[code_desc0] = code_32bit_ring0;
    g_gdt[data_desc0] = data_32bit_ring0;
    g_gdt[sysentercode_desc0] = code_32bit_ring0;
    g_gdt[sysenterdata_desc0] = data_32bit_ring0;
    g_gdt[sysentercode_desc3] = code_32bit_ring3;
    g_gdt[sysenterdata_desc3] = data_32bit_ring3;
    g_gdt[tssdesc_cpu0..tssdesc_cpu(maxcpus-1)] = g_tss[0..(maxcpus-1)];

    //initialize TSS
    g_tss[0..(maxcpus-1)].ss0 = data_desc0;
    g_tss[0..(maxcpus-1)].esp0 = g_tsstack[0..(maxcpus-1)];
    g_tss[0..(maxcpus-1)].iobitmap = g_iotbl[0..(maxcpus-1)];

    //initialize IDT
    g_idt[0..maxexceptions-1] = g_sinfotable[GEEC_SENTINEL].memoffets[2..(maxexceptions-1)+2]

    g_replicate_cr3 = hw.cpu.cr3;
    g_replicate_cr4 = hw.cpu.cr4;
    g_replicate_msrefer = hw.cpu.msrefer;
    g_replicate_cr0 = hw.cpu.cr0;

    hw.lapic.command_register |= WAKE_APS at gp_common_state

    gp_common_state();

    halt();
}


gp_common_state {

    l_cpuid = hw.lapic.id;
    hw.cpu.esp = g_stack[cpuid];
    hw.cpu.cr3 = g_replicate_cr3;
    hw.cpu.cr4 = g_replicate_cr4;
    hw.cpu.cr0 = g_replicate_cr0;

    setup unverified_guest_slab VMCS support via:
    gp_call_slab(UAPI_CPUSTATE, UAPI_CPUSTATE_VMREAD);
    gp_call_slab(UAPI_CPUSTATE, UAPI_CPUSTATE_VMWRITE);
    gp_call_slab(UAPI_CPUSTATE, UAPI_CPUSTATE_RDMSR);
    gp_call_slab(UAPI_CPUSTATE, UAPI_CPUSTATE_WRMSR);

    hw.cpu.vmxon = true
    hw.cpu.vmcsbase = g_sinfotable[UAPI_CPUSTATE].memoffsets[0];
    hw.cpu.sysenterhandler = g_sinfotable[GEEC_SENTINEL].memoffsets[0];
    hw.cpu.sysenterstack = g_sysenterstack[cpuid];
    hw.cpu.vmexithandler = g_sinfotable[GEEC_SENTINEL].memoffsets[1];

    gp_call_slab(INIT_SLAB, 0);

    halt();

}

